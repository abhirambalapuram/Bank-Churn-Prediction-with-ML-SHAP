# -*- coding: utf-8 -*-
"""bank_churn_ml_shap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x0Fuo6hilVo9oTI4rrb38BLgiiuhiT4k
"""

!pip -q install imbalanced-learn xgboost shap

import os, sys, glob, warnings, textwrap, numpy as np, pandas as pd
from pathlib import Path
warnings.filterwarnings("ignore")

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE

from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,
    classification_report, confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay
)

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier

import shap, joblib
shap.__version__
RANDOM_STATE = 42

plt.rcParams["figure.figsize"] = (8,5)
plt.rcParams["axes.grid"] = True
sns.set_context("notebook")

import pandas as pd

CSV_PATH = "Churn_Modeling.csv"
df = pd.read_csv("/content/Churn_Modeling.csv")

print(f"Loaded: {CSV_PATH} | shape: {df.shape}")
display(df.head())

print(df.info())
print("\nHead:")
display(df.head())

# Guess the target column robustly
TARGET_CANDIDATES = ["Exited", "Churn", "churn", "Target", "y"]
target = None
for c in TARGET_CANDIDATES:
    if c in df.columns:
        target = c
        break
if target is None:
    raise ValueError("Target column not found. Make sure your file has an 'Exited' (or similar) column.")

print("\nTarget column detected:", target)

# Drop common ID-like columns if present
ID_COLS = {"RowNumber","CustomerId","Surname","id","customerid","name","CustomerID","AccountNumber"}
to_drop = [c for c in df.columns if c in ID_COLS]
print("Dropping ID-like columns:", to_drop)
df = df.drop(columns=to_drop)

# Basic target distribution
ax = df[target].value_counts(normalize=True).sort_index().plot(kind="bar")
ax.set_title("Target distribution (share)")
ax.set_xlabel(target)
ax.set_ylabel("Proportion")
plt.show()

y = df[target].astype(int)
X = df.drop(columns=[target])

# Identify column types
num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()
print("Numeric columns:", num_cols)
print("Categorical columns:", cat_cols)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y
)
X_train.shape, X_test.shape

# Correlation on numeric columns
if len(num_cols) > 1:
    corr = X[num_cols].corr()
    sns.heatmap(corr, cmap="coolwarm", center=0)
    plt.title("Numeric feature correlation")
    plt.show()

# some distributions
cols_to_plot = (num_cols[:4] if len(num_cols) >= 4 else num_cols) + (cat_cols[:2] if len(cat_cols)>=2 else cat_cols)
for c in cols_to_plot:
    plt.figure()
    if c in num_cols:
        sns.histplot(data=df, x=c, hue=target, kde=True, stat="density", common_norm=False)
        plt.title(f"Distribution of {c} by {target}")
    else:
        sns.countplot(data=df, x=c, hue=target)
        plt.title(f"Counts of {c} by {target}")
        plt.xticks(rotation=30, ha="right")
    plt.tight_layout()
    plt.show()

ohe_kwargs = dict(drop="first", handle_unknown="ignore")
try:
    ohe = OneHotEncoder(sparse_output=True, **ohe_kwargs)  # sklearn >= 1.2
except TypeError:
    ohe = OneHotEncoder(sparse=True, **ohe_kwargs)         # sklearn < 1.2

numeric_pipe = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler(with_mean=False))
])

categorical_pipe = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("ohe", ohe)
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_pipe, num_cols),
        ("cat", categorical_pipe, cat_cols)
    ],
    remainder="drop",
    sparse_threshold=0.3
)

# Helper to fetch transformed feature names
def get_feature_names(fitted_preproc, num_cols=num_cols, cat_cols=cat_cols):
    names = []
    if num_cols:
        names.extend(list(num_cols))
    if cat_cols:
        ohe_fitted = fitted_preproc.named_transformers_["cat"].named_steps["ohe"]
        # Trying new API first
        if hasattr(ohe_fitted, "get_feature_names_out"):
            names.extend(list(ohe_fitted.get_feature_names_out(cat_cols)))
        else:
            names.extend(list(ohe_fitted.get_feature_names(cat_cols)))
    return np.array(names)

def evaluate_classifier(clf, X_tr, y_tr, X_te, y_te, label="model"):
    y_hat = clf.predict(X_te)
    y_prob = None
    try:
        y_prob = clf.predict_proba(X_te)[:, 1]
    except Exception:
        try:
            y_prob = clf.decision_function(X_te)
        except Exception:
            pass

    metrics = {
        "model": label,
        "accuracy": accuracy_score(y_te, y_hat),
        "precision": precision_score(y_te, y_hat, zero_division=0),
        "recall": recall_score(y_te, y_hat, zero_division=0),
        "f1": f1_score(y_te, y_hat, zero_division=0),
        "roc_auc": roc_auc_score(y_te, y_prob) if y_prob is not None else np.nan
    }

    print(f"\n=== {label} ===")
    print(pd.Series(metrics))
    print("\nClassification Report:\n", classification_report(y_te, y_hat, zero_division=0))

    cm = confusion_matrix(y_te, y_hat)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(f"Confusion Matrix — {label}")
    plt.xlabel("Predicted"); plt.ylabel("Actual")
    plt.show()

    if y_prob is not None:
        RocCurveDisplay.from_predictions(y_te, y_prob)
        plt.title(f"ROC Curve — {label}")
        plt.show()

        PrecisionRecallDisplay.from_predictions(y_te, y_prob)
        plt.title(f"Precision-Recall Curve — {label}")
        plt.show()

    return metrics

models = {
    "LogReg": LogisticRegression(max_iter=1000, solver="lbfgs"),
    "KNN": KNeighborsClassifier(n_neighbors=15),
    "SVC": SVC(kernel="rbf", probability=True, random_state=RANDOM_STATE),
    "RF": RandomForestClassifier(
        n_estimators=300, max_depth=None, min_samples_split=4,
        random_state=RANDOM_STATE, n_jobs=-1
    ),
    "GB": GradientBoostingClassifier(random_state=RANDOM_STATE),
    "XGB": XGBClassifier(
        n_estimators=400, max_depth=5, learning_rate=0.05, subsample=0.9,
        colsample_bytree=0.9, random_state=RANDOM_STATE, eval_metric="logloss", n_jobs=-1
    )
}

results_plain = []
for name, model in models.items():
    pipe = Pipeline(steps=[("pre", preprocessor), ("clf", model)])
    pipe.fit(X_train, y_train)
    metrics = evaluate_classifier(pipe, X_train, y_train, X_test, y_test, label=f"{name}_plain")
    results_plain.append(metrics)

df_plain = pd.DataFrame(results_plain).set_index("model").sort_values("f1", ascending=False)
display(df_plain)

ax = df_plain[["accuracy","precision","recall","f1","roc_auc"]].plot(kind="bar")
ax.set_title("Model comparison (no SMOTE)")
plt.xticks(rotation=30, ha="right")
plt.tight_layout()
plt.show()

results_smote = []
for name, model in models.items():
    smote_pipe = ImbPipeline(steps=[
        ("pre", preprocessor),
        ("smote", SMOTE(random_state=RANDOM_STATE)),
        ("clf", model)
    ])
    smote_pipe.fit(X_train, y_train)
    metrics = evaluate_classifier(smote_pipe, X_train, y_train, X_test, y_test, label=f"{name}_SMOTE")
    results_smote.append(metrics)

df_smote = pd.DataFrame(results_smote).set_index("model").sort_values("f1", ascending=False)
display(df_smote)

ax = df_smote[["accuracy","precision","recall","f1","roc_auc"]].plot(kind="bar")
ax.set_title("Model comparison (with SMOTE on train only)")
plt.xticks(rotation=30, ha="right")
plt.tight_layout()
plt.show()

best_label = df_smote["f1"].idxmax()
print("Best (by F1) from SMOTE runs:", best_label)

# Extract base key
base_key = best_label.split("_")[0]
best_model = models[base_key]

best_pipe = ImbPipeline(steps=[("pre", preprocessor),
                               ("smote", SMOTE(random_state=RANDOM_STATE)),
                               ("clf", best_model)])
scores = cross_val_score(best_pipe, X_train, y_train, cv=5, scoring="f1", n_jobs=-1)
print("5-fold CV F1 mean ± std:", scores.mean().round(4), "±", scores.std().round(4))

best_pipe.fit(X_train, y_train)
_ = evaluate_classifier(best_pipe, X_train, y_train, X_test, y_test, label=f"{base_key}_SMOTE(final)")

from sklearn.model_selection import RandomizedSearchCV
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier

# Pipeline: preprocessing + SMOTE + RF
rf_pipe = ImbPipeline(steps=[
    ("pre", preprocessor),
    ("smote", SMOTE(random_state=RANDOM_STATE)),
    ("clf", RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1))
])

# Lightweight search space (good balance of quality/speed)
param_distributions = {
    "clf__n_estimators":    [150, 250, 350, 450],
    "clf__max_depth":       [None, 6, 8, 10],
    "clf__min_samples_split":[2, 4, 6, 8],
    "clf__min_samples_leaf":[1, 2, 3],
    "clf__max_features":    ["sqrt", "log2", None],
    # Subsample for speed without much loss
    "clf__max_samples":     [None, 0.8, 0.6],
}

rs = RandomizedSearchCV(
    rf_pipe,
    param_distributions=param_distributions,
    n_iter=18,
    scoring="f1",
    cv=3,
    n_jobs=-1,
    verbose=1,
    random_state=RANDOM_STATE
)

rs.fit(X_train, y_train)
print("Best params:", rs.best_params_)
print("Best CV F1:", round(rs.best_score_, 4))

rf_best = rs.best_estimator_
_ = evaluate_classifier(rf_best, X_train, y_train, X_test, y_test, label="RF_SMOTE(tuned_fast)")

preprocessor_fit = preprocessor.fit(X_train, y_train)
feature_names = get_feature_names(preprocessor_fit)
print("Transformed feature count:", len(feature_names))
feature_names[:15]

rf_for_importance = None
if "rf_best" in globals():
    rf_for_importance = rf_best
else:
    if base_key == "RF":
        rf_for_importance = best_pipe
    else:
        temp_rf = ImbPipeline(steps=[("pre", preprocessor),
                                     ("smote", SMOTE(random_state=RANDOM_STATE)),
                                     ("clf", RandomForestClassifier(
                                         n_estimators=400, random_state=RANDOM_STATE, n_jobs=-1))])
        temp_rf.fit(X_train, y_train)
        rf_for_importance = temp_rf

inner_rf = rf_for_importance.named_steps["clf"]
importances = inner_rf.feature_importances_

imp_df = pd.DataFrame({"feature": feature_names, "importance": importances}).sort_values("importance", ascending=False)
display(imp_df.head(20))

sns.barplot(data=imp_df.head(20), x="importance", y="feature")
plt.title("Top 20 feature importances (RF)")
plt.tight_layout()
plt.show()

import numpy as np
import shap

def to_dense(M):
    return M.toarray() if hasattr(M, "toarray") else np.asarray(M)


rf_pipe_used = rf_for_importance
model = rf_pipe_used.named_steps["clf"]


preproc_used = rf_pipe_used.named_steps["pre"]


X_train_trans = preproc_used.transform(X_train)
X_test_trans  = preproc_used.transform(X_test)

X_train_dense = to_dense(X_train_trans)
X_test_dense  = to_dense(X_test_trans)


feature_names = get_feature_names(preproc_used)
print("Transformed shapes — train:", X_train_dense.shape, "| test:", X_test_dense.shape, "| features:", len(feature_names))

# Background sample for stability/speed
rng = np.random.RandomState(42)
bg_n = min(200, X_train_dense.shape[0])
bg_idx = rng.choice(np.arange(X_train_dense.shape[0]), size=bg_n, replace=False)
background = X_train_dense[bg_idx]


try:
    explainer = shap.TreeExplainer(model, data=background, feature_perturbation="interventional")
    shap_values = explainer.shap_values(X_test_dense)

    if isinstance(shap_values, list):
        shap_values = shap_values[1]
except Exception as e:
    print("TreeExplainer fallback due to:", e)
    explainer = shap.Explainer(model, background)
    shap_values = explainer(X_test_dense).values

print("SHAP values shape:", np.array(shap_values).shape)
print("X_test_dense shape:", X_test_dense.shape)

# Ensuring shapes match before plotting
assert shap_values.shape[1] == X_test_dense.shape[1], \
    "SHAP-feature dimension mismatch. Ensure Cells 14–15 used the SAME fitted preprocessor/pipeline."

# Plots
shap.summary_plot(shap_values, features=X_test_dense, feature_names=feature_names, plot_type="bar", show=True)
shap.summary_plot(shap_values, features=X_test_dense, feature_names=feature_names, show=True)

out_dir = Path("artifacts"); out_dir.mkdir(exist_ok=True)
joblib.dump(rf_pipe_used, out_dir / "churn_model_rf_pipeline.joblib")
np.save(out_dir / "feature_names.npy", feature_names)
print("Saved to:", out_dir.resolve())

# Predicting churn probability for first 5 rows from test set
proba = rf_pipe_used.predict_proba(X_test)[:, 1]
demo = pd.DataFrame({
    "prob_churn": proba[:5],
    "actual": y_test.iloc[:5].values
}).round(4)
display(pd.concat([X_test.iloc[:5].reset_index(drop=True), demo], axis=1))